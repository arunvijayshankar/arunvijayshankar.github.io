<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-12-24T15:44:47-08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Arktos kai Mennos</title><subtitle>Arun Vijayshankar's blog</subtitle><entry><title type="html">Run a command recursively in all subdirectories</title><link href="http://localhost:4000/archive/run-a-command-recursively-in-all-subdirectories/" rel="alternate" type="text/html" title="Run a command recursively in all subdirectories" /><published>2022-12-23T00:00:00-08:00</published><updated>2022-12-23T00:00:00-08:00</updated><id>http://localhost:4000/archive/run-a-command-recursively-in-all-subdirectories</id><content type="html" xml:base="http://localhost:4000/archive/run-a-command-recursively-in-all-subdirectories/">&lt;p&gt;Suppose you wish to run a linux command in the current working directory, and in all of its subdirectories recursively. For example, I discovered that sometimes, running ‘make modules_install’ compresses all the modules as a .xz file in the various subdirectories. I read that the kernel does not care if a module is compressed, it can load the module in any case, but I did not know that at the time. I initially considered running “xz –decompress “ on every .xz file, but there are simply too many subsystem and driver directories, and it would extremely tedious. So I wrote a little script to do it:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/arunvijayshankar/a61fb0cd840f86e5f9ad4d4132497bf9&quot;&gt;run_cmd.py&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&quot;&quot;&quot;
* Script to run a system command recursively in every subdirectory 
* in a directory, including the current working directory
* Usage: run_cmd.py -[si] -c &amp;lt;command-to-run&amp;gt;
*
* Options:
*   -i 
*       Interactive mode. Prompts user to choose whether or not to 
*       run the command in a directory
*   -s
*       Skips the command for the working directory
*   -c
*       Command to be run
*
* Example: $python run_cmd.py -s -c &amp;lt;command-to-run&amp;gt;
* This will run 'ls -l &amp;gt; contents.txt' in every subdirectory in the tree
* recursively, but will not run it in the working directory
*
* Author: Arun Vijayshankar
&quot;&quot;&quot;

import getopt
import os
import sys

def recursive_run_cmd_inter(root, cmd):
    for file in os.listdir(root):
        d = os.path.join(root, file)
        if os.path.isdir(d):
            os.chdir(d)
            run = input(&quot;Do you want to run &quot; + cmd + &quot; in: \n&quot; + os.getcwd() + &quot; [Y/No]&quot;)
            if str(run).upper() in ['Y', 'YES']:
                print(&quot;running &quot; + cmd + &quot; in: &quot; + os.getcwd())
                os.system(cmd)
            recursive_run_cmd_inter(d, cmd)

def recursive_run_cmd(root, cmd):
    for file in os.listdir(root):
        d = os.path.join(root, file)
        if os.path.isdir(d):
            os.chdir(d)
            print(&quot;running &quot; + cmd + &quot; in: &quot; + os.getcwd())
            os.system(cmd)
            recursive_run_cmd(d, cmd)
            
def entry():
    argv = sys.argv[1:]
    try:
        options, args = getopt.getopt(argv, &quot;s:i:c&quot;, [])
    except:
        print(&quot;Usage: run_cmd.py -[si] -c '&amp;lt;command-to-be-run&amp;gt;'&quot;)

    root = os.getcwd()
    cmd = args[0]
    print(cmd)

    if '-i' in options[0]:
        recursive_run_cmd_inter(root, cmd)
    if '-s' in options[0]:
        if '-i' in options[0]:
            recursive_run_cmd_inter(root, cmd)
        else:
            recursive_run_cmd(root, cmd)
    else:
        os.chdir(root)
        print(&quot;running &quot; + cmd + &quot; in: &quot; + os.getcwd())
        os.system(cmd)
        recursive_run_cmd(root, cmd)

if __name__ == &quot;__main__&quot;:
    entry()

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I tested it out on Ubuntu 20.04, and it seems to work. An addition that could be made is maybe the script can take a list of directory in which to run the command and run it in those only. I mightget around to doing this someday very soon.&lt;/p&gt;</content><author><name>Arun</name></author><category term="programming" /><category term="python" /><category term="linux" /><summary type="html">Suppose you wish to run a linux command in the current working directory, and in all of its subdirectories recursively. For example, I discovered that sometimes, running ‘make modules_install’ compresses all the modules as a .xz file in the various subdirectories. I read that the kernel does not care if a module is compressed, it can load the module in any case, but I did not know that at the time. I initially considered running “xz –decompress “ on every .xz file, but there are simply too many subsystem and driver directories, and it would extremely tedious. So I wrote a little script to do it:</summary></entry><entry><title type="html">A simple two channel multiplexer</title><link href="http://localhost:4000/archive/a-simple-two-channel-multiplexer/" rel="alternate" type="text/html" title="A simple two channel multiplexer" /><published>2022-11-29T00:00:00-08:00</published><updated>2022-11-29T00:00:00-08:00</updated><id>http://localhost:4000/archive/a-simple-two-channel-multiplexer</id><content type="html" xml:base="http://localhost:4000/archive/a-simple-two-channel-multiplexer/">&lt;p&gt;A couple of weeks ago, I came across this equation for a two channel multiplexer in a book on x86 Assembly&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Z = ( Y &amp;amp; S ) | ( X &amp;amp; ~S )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I was a little surprised at how simple the equation was and, out of curiosity, I drew a quick schematic of it&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post10/mplexer_schem.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It occured to me that I could build this for a simple and fun project. I had never really built any circuits before, and this seemed like a good first attempt. So I ordered the logic gates, and put it together once they were delivered, a few days later. It’s a very simple circuit and it was really easy to build.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post10/mplexer_pic.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I used my beaglebone board to power the circuit, and for the input data streams for the two channels on the multiplexer. For the inputs I chose two pwm signals of 2Hz and 5Hz respectively and forwarded them from GPIO header pins on the beaglebone black. I kept the pwm signal frequency low to make the channel selection easier to observe. The circuit uses a push-button to flip the selection channel to choose between the two input channels. Here is a small demo of the circuit in action.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post10/demo_final_gif.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>Arun</name></author><category term="programming" /><category term="digital-circuits" /><summary type="html">A couple of weeks ago, I came across this equation for a two channel multiplexer in a book on x86 Assembly</summary></entry><entry><title type="html">An embedded graphics framebuf driver for mnemOS</title><link href="http://localhost:4000/archive/an-embedded-graphics-framebuf-driver/" rel="alternate" type="text/html" title="An embedded graphics framebuf driver for mnemOS" /><published>2022-08-05T00:00:00-07:00</published><updated>2022-08-05T00:00:00-07:00</updated><id>http://localhost:4000/archive/an-embedded-graphics-framebuf-driver</id><content type="html" xml:base="http://localhost:4000/archive/an-embedded-graphics-framebuf-driver/">&lt;p&gt;Recently, I wrote a graphics framebuffer driver using the &lt;a href=&quot;https://docs.rs/embedded-graphics/latest/embedded_graphics/&quot;&gt;embedded-graphics crate&lt;/a&gt;. The driver was written for &lt;a href=&quot;https://mnemos-dev.jamesmunns.com/book/intro.html&quot;&gt;mnemOS&lt;/a&gt;, an operating system written in Rust. This contributions marks many firsts for me; first contribution to an OSS project, first piece of embedded software written, first driver written. The driver it self is quite simple. We use &lt;a href=&quot;https://docs.rs/embedded-graphics-simulator/latest/embedded_graphics_simulator/&quot;&gt;embedded-graphics-simulator&lt;/a&gt; to create a GUI window to display objects/text on. The driver then gives the user a chunk of heap memory onto which an object is drawn. ‘Draw’ is a trait in embedded-graphics where, given a collection of pixels each with a color and coordinate (the object), each pixel’s colour and coordinate (for 8bpp images) is stored in one byte of memory. The entire object can then be stored in a heap array.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post9/2022-08-05-21-40-33.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Once the object has been drawn onto the chunk of memory, it can then be passed to the e-g-simulator window where it is displayed. However, as the e-g-simulator window only takes a ‘SimulatorDisplay’ object as an argument, the driver converts the raw bytes into an ‘image’, which can be passed back to user space and displayed on the window. If we are using a physical display, like a simple OLED display, the raw bytes can be sent over a suitable interface like SPI or I2C. Here is a sample what it looks like on the e-g-simulator:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/gifs/Screencast_from_07-27-2022_11_23_56_AM_AdobeExpress.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Contributing to an open source project (or any project, really) has been a goal of mine ever since I started learning programming in earnest. It was really rewarding to go from dreaming about making a contribution, to actually doing it. A small part of me still cannot believe I did it. I owe a huge shoutout to James Munns &lt;a href=&quot;https://twitter.com/bitshiftmask&quot;&gt;(@bitshiftmask)&lt;/a&gt; for encouraging me to just give it try when I expressed my desire to help out with this issue, but confessed that I wasn’t sure if I knew enough to do it. With this under my belt, I feel a lot more confident about my skills, and I am rearing to take on more projects and tasks. Next up is writing a networking driver for mnemOS using smoltcp, a TCP/IP stack for embedded/bare-metal rust projects. I plan to work on this in conjunction with continuing my learning journey in embedded systems.&lt;/p&gt;</content><author><name>Arun</name></author><category term="programming" /><category term="embedded" /><category term="device-drivers" /><category term="rust" /><summary type="html">Recently, I wrote a graphics framebuffer driver using the embedded-graphics crate. The driver was written for mnemOS, an operating system written in Rust. This contributions marks many firsts for me; first contribution to an OSS project, first piece of embedded software written, first driver written. The driver it self is quite simple. We use embedded-graphics-simulator to create a GUI window to display objects/text on. The driver then gives the user a chunk of heap memory onto which an object is drawn. ‘Draw’ is a trait in embedded-graphics where, given a collection of pixels each with a color and coordinate (the object), each pixel’s colour and coordinate (for 8bpp images) is stored in one byte of memory. The entire object can then be stored in a heap array.</summary></entry><entry><title type="html">What is scull</title><link href="http://localhost:4000/archive/what-is-scull/" rel="alternate" type="text/html" title="What is scull" /><published>2022-07-06T00:00:00-07:00</published><updated>2022-07-06T00:00:00-07:00</updated><id>http://localhost:4000/archive/what-is-scull</id><content type="html" xml:base="http://localhost:4000/archive/what-is-scull/">&lt;h2 id=&quot;scull-simple-character-utility-for-loading-localities&quot;&gt;Scull: Simple Character Utility for Loading Localities&lt;/h2&gt;

&lt;p&gt;“scull is char driver that acts on a memory area as though it were a device.”, is how scull is described in chapter 3 of 
&lt;a href=&quot;https://lwn.net/Kernel/LDD3/&quot;&gt;Linux Device Drivers&lt;/a&gt;. That seemed straightforward enough. Scull’s capabilities and allowed operations are described
in detail in the rest of the chapter. Once I finished the chapter, I wanted to learn more about what exactly scull was, and how I could go about
using it. But there seems to be surprisingly little information about it online. I thought I’d write a little something about what I have learned about 
it so far.&lt;/p&gt;

&lt;p&gt;Scull, if I understand it correctly, is fundamentally a kernel module. When the module is loaded, using insmod or modprobe, the kernel allocates some 
memory for scull, which then treats that memory region like a character device. Once loaded, scull will show up in /proc/devices:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post8/proc_devices.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A user can then use it as they would a regular character device. One can open and close it, read from it, or write to it.&lt;/p&gt;

&lt;p&gt;The source code for scull can be found &lt;a href=&quot;http://gauss.ececs.uc.edu/Courses/c4029/code/drivers/Scull/scull.html&quot;&gt;here&lt;/a&gt;. It can be compiled as a module 
by extracting the files from that archive and running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make&lt;/code&gt; at the source directory. Loading and Unloading of the module can be done using scull.load 
and scull.unload respectively. The shell scripts also clean up stale filesystem nodes, and setup new ones after loading the module. The newly created 
nodes will now show up under /dev:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post8/ls_dev.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;device-types-and-supported-operations&quot;&gt;Device types and supported operations&lt;/h2&gt;

&lt;p&gt;Scull supports different types of devices:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;scull0 - scull3
    &lt;ul&gt;
      &lt;li&gt;These are global and persistant, meaning the data stored in them is shared between all the open file descriptors associated with it, and that the data is not lost if a file descriptor is closed.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;scullpipe0 - scullpipe3
    &lt;ul&gt;
      &lt;li&gt;These are FIFO devices which act as pipes.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;scullsingle, scullpriv, sculluid, scullwuid
    &lt;ul&gt;
      &lt;li&gt;These are similar to scull0, with limitations on when open can be called on them.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Scull implements the following basic device methods:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;llseek():     Change current read/write position in a file.&lt;/li&gt;
  &lt;li&gt;read():       Retrieve data from the device.&lt;/li&gt;
  &lt;li&gt;write():      Write data to the device.&lt;/li&gt;
  &lt;li&gt;open():       First operation performed on the file.&lt;/li&gt;
  &lt;li&gt;ioctl():      Issue device specific commands, which are neither reading or writing.&lt;/li&gt;
  &lt;li&gt;release():    Invoked when file structure is released.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;using-scull&quot;&gt;Using scull&lt;/h2&gt;

&lt;p&gt;To use scull, we have have to first compile it to create scull module. The Makefile in the distribution comes configured, so all that needs to be done
is to run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo make&lt;/code&gt; from the source directory&lt;sup&gt;*&lt;/sup&gt;. You would need a machine running a linux kernel to compile it successfully, I’m pretty sure. Once the module is compiled and ready to be loaded, run the scull.load bash script to load the module, and create the filesystem nodes.&lt;/p&gt;

&lt;p&gt;The scull device is now ready to be written to, and read from. The scull distribution comes with a test file: sculltest.c&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/* sculltest.c
 * A simple example of a C program to test some of the
 * operations of the &quot;/dev/scull&quot; device (a.k.a &quot;scull0&quot;),
 * and the 
 * ($Id: sculltest.c,v 1.1 2010/05/19 20:40:00 baker Exp baker $)
 */
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;

int main() {
   int fd, result, len;
   char buf[10];
   const char *str;
   if ((fd = open(&quot;/dev/scull&quot;, O_WRONLY)) == -1) {
      perror(&quot;1. open failed&quot;);
      return -1;
   }

   str = &quot;abcde&quot;; 
   len = strlen(str);
   if ((result = write(fd, str, len)) != len) {
      perror(&quot;1. write failed&quot;);
      return -1;
   }
   close(fd);

   if ((fd = open(&quot;/dev/scull&quot;, O_RDONLY)) == -1) {
      perror(&quot;2. open failed&quot;);
      return -1;
   }
   if ((result = read(fd, &amp;amp;buf, sizeof(buf))) != len) {
      fprintf(stdout, &quot;1. read failed, buf=%s&quot;,buf);
      return -1;
   } 
   buf[result] = '\0';
   if (strncmp (buf, str, len)) {
      fprintf (stdout, &quot;failed: read back \&quot;%s\&quot;\n&quot;, buf);
   } else {
      fprintf (stdout, &quot;passed\n&quot;);
   }
   close(fd);

   ---SNIP---
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Once the module is loaded, sculltest.c can be compiled and run to test out open, read, and write. Upon a read or write syscall, the corresponding 
function implemented in scull is called. The user can of course, write their own tests to test out supported operations.&lt;/p&gt;

&lt;p&gt;To gain a better understanding of scull and char drivers in general, I implemented a minimalistic version that supports only basic open/close, read/write operations, and only supports the global, persistant scull device type (scull0 - scull3). It can be found &lt;a href=&quot;https://github.com/arunvijayshankar/vichy&quot;&gt;here&lt;/a&gt;. The other major difference is the memory layout. In scull, each device is a linked list of structures, each of which points to a memory area of 4MB at most, though an array of a 1000 pointers, each pointing to a memory area of 4000 bytes. In vichy, each structure in the linked list making up the device points to just one memory area of 4000 bytes. These changes necessitated a few changes in the actual code, but they are small and cosmetic. Which is ok, I think. As a learner, it is a good confidence boost to make small changes to a project and learn by debugging all the issues you run into. This way you can learn the technology, and gain some actual coding experience.&lt;/p&gt;

&lt;p&gt;&lt;sup&gt;*&lt;/sup&gt;Note: On newer kernels (I’m running 5.19.0-rc3), scull hits compilations errors, mostly due to a deprecated method. The errors can be fixed with these patches&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;main.c: https://gist.github.com/arunvijayshankar/213e4dc0442ad3f4cd2b9785abc878a7&lt;/li&gt;
  &lt;li&gt;pipe.c: https://gist.github.com/arunvijayshankar/1cd5a2672fe540e196e9c27d163b0407&lt;/li&gt;
  &lt;li&gt;access.c: https://gist.github.com/arunvijayshankar/ae12566ac20707eb43afdf3e3d05a570&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Arun</name></author><category term="programming" /><category term="c" /><category term="linux" /><category term="device-drivers" /><summary type="html">Scull: Simple Character Utility for Loading Localities</summary></entry><entry><title type="html">Cross Compiling for BeagleBoard targets, and benchmarks</title><link href="http://localhost:4000/archive/cross-compiling-for-beagleboard-and-benchmarks/" rel="alternate" type="text/html" title="Cross Compiling for BeagleBoard targets, and benchmarks" /><published>2022-06-30T00:00:00-07:00</published><updated>2022-06-30T00:00:00-07:00</updated><id>http://localhost:4000/archive/cross-compiling-for-beagleboard-and-benchmarks</id><content type="html" xml:base="http://localhost:4000/archive/cross-compiling-for-beagleboard-and-benchmarks/">&lt;p&gt;I have been using a BeagleBoard-xM as a target for the recepies in the book Embedded Programming with Modern C++ Cookbook, and here are a few of the interesting things I’ve come across:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h2 id=&quot;cross-compiler&quot;&gt;Cross Compiler&lt;/h2&gt;
    &lt;p&gt;The book uses a Raspberry Pi emulator on QEMU as a target, and uses the gcc/g++ arm cross compiler (arm-linux-gnueabi-gcc/g++) to build the binaries. As the RPi and BeagleBoard both run arm processors, I assumed that a binary that runs on Raspberry Pi would work on BeagleBoard as well. Spoiler alert: a binary compiled to run on an RPi, will not run on BeagleBoard. Google-fu helped me understand that the BeagleBoard needs a slightly different cross-compiler: arm-linux-gnueabi&lt;strong&gt;hf&lt;/strong&gt;-gcc/g++. Once I changed the Cmake file accordingly, I could run the program on BeagleBoard.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h2 id=&quot;uninitialized-pointers&quot;&gt;Uninitialized Pointers&lt;/h2&gt;
    &lt;p&gt;A small program that would create a shared memory region and then have two processes read from, and write to it, gave me unexpected results (and sometimes hit segmentation faults on the last read) on the beagleboard and RPi, whereas on the build system it crashed immediately. It turned out that I was derefencing an uninitialized pointer. On the build system the offending pointer was set to 0x0, but on the bbxm and raspberry pi, it was set to a random pointer. I’m not sure if this is something to do with the architecture or the compiler.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h2 id=&quot;system-timer&quot;&gt;System Timer&lt;/h2&gt;
    &lt;p&gt;One of the exercises involved writing a program to read the system timer on the rpi. This was a little bit of a challenge to port to the BBxM as the beagleboard’s system timer was structured a little differently. I wrote about this in more detail &lt;a href=&quot;https://arunvijayshankar.github.io/archive/reading-sync-timer-beagleboard-xm/&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h2 id=&quot;benchmarks&quot;&gt;Benchmarks&lt;/h2&gt;
    &lt;p&gt;Finally I ran lmbench on the build system, an x86_64 machine running ubuntu, and on the beagleboard, which is armv7 running debian:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;BeagleBoard-xM benchmarks&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post7/bbxm_bench.png&quot; alt=&quot;BeagleBoard-xM Benchmarks&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Build system benchmarks&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post7/x86_bench.png&quot; alt=&quot;Build system (x86_64) Benchmarks&quot; /&gt;&lt;/p&gt;</content><author><name>Arun</name></author><category term="programming" /><category term="c" /><category term="cpp" /><category term="embedded" /><summary type="html">I have been using a BeagleBoard-xM as a target for the recepies in the book Embedded Programming with Modern C++ Cookbook, and here are a few of the interesting things I’ve come across:</summary></entry><entry><title type="html">Reading the System Timer on Beagleboard XM</title><link href="http://localhost:4000/archive/reading-sync-timer-beagleboard-xm/" rel="alternate" type="text/html" title="Reading the System Timer on Beagleboard XM" /><published>2022-06-10T00:00:00-07:00</published><updated>2022-06-10T00:00:00-07:00</updated><id>http://localhost:4000/archive/reading-sync-timer-beagleboard-xm</id><content type="html" xml:base="http://localhost:4000/archive/reading-sync-timer-beagleboard-xm/">&lt;p&gt;One of the exercises in the book ‘Embedded Programming with Modern C++ Cookbook’ is to read the System Timer on a RaspberryPi. The system timer peripheral on a raspberry pi provides a 64 bit free running counter that increments with every clock tick. Although the book uses QEMU to run a rPi emulator as the target for the programs, I have been using a Beagleboard XM as the target. So far, there have been some changes, but no significant differences in code for the raspberry pi vs the beagleboard. I assumed that reading the system timer would be no different. This was of course, not the case. For a beginner like myself, it was quite challenging to get it working on the bbxm.&lt;/p&gt;

&lt;p&gt;The book starts off by hard coding the base address of the rPi system timer, and a struct to store the two 32 bit sections of the timer:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;constexpr uint32_t kTimerBase = 0x3F003000;

struct SystemTimer {
  uint32_t CS;
  uint32_t counter_lo;
  uint32_t counter_hi;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The sync timer address is then mapped using mmap as a shared map and cast as a struct pointer to read the value into counter_lo and counter_hi, which are added together to get the actual timer value.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int memfd = open(&quot;/dev/mem&quot;, O_RDWR | O_SYNC);

SystemTimer *timer = (SystemTimer*)mmap(NULL, sizeof(SystemTimer),
PROT_READ|PROT_WRITE, MAP_SHARED,
memfd, kTimerBase);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I knew that it was unlikely that the timer base address will be the same on the bbxm, so the first challenge was to find the right address. I looked for the AM37 manual online, and it turns out that Texas Instruments will let you download it if you register an account with them. So now I have a TI developer account. Oh, and the manual. The manual listed the Sync Timer base address of the 32 kHz clock as 0x48320000, and that the register was 32 bits long. I made the changes, and compiled the build. But when I ran it, the program would only print out one value&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;System timer: 64
System timer: 64
System timer: 64
System timer: 64
System timer: 64
System timer: 64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It looked as if the timer was not updating with every clock tick. My first suspicion was that address was wrong somehow, or that the mapping was not correct. I spent a considerable amount of time trying to get to the bottom of that, all to no avail. The address was as noted in the manual, and there did not seem to be anything wrong with the mapping. So I did the only thing I could think of, and reached out to the good folks on the internet. One person suggested that maybe the timer was not enabled. This seemed like a plausible root cause, so I went back to the manual and started digging to find out how to check if the timer is disabled. I did find the timer controls, but I honestly did not really understand it. But what I did accidentally discover was that even though the base address for the sync timer on the bbxm is 0x48320000, the actual value of the timer is stored at a 0x0010 offset!&lt;/p&gt;

&lt;p&gt;So I dutifully changed the address to 0x48320010, re-compiled, and ran it. I hit a Bus Error. What is a bus error now? I asked my browser, which said that it was a hardware error, letting the OS know that CPU cannot access the memory that the process is trying to access. So I was back to some issue with the address. I was convinced that the physical address was correct this time, so maybe there was something wrong with the virtual address? After some more scouring of the internet, I found this &lt;a href=&quot;https://bakhi.github.io/devmem/&quot;&gt;post&lt;/a&gt;. Reading through it, I finally understood that mmap was creating a new mapping in the virtual address space starting at the physical address we specify in the mmap call. For some reason that I don’t still understand, providing the physical address + the offset to mmap was returning a bad virtual address. But maybe mapping the timer base address first, and then adding the offset might fix it? I tried this, and it worked! The value updated by ~400 units everytime I ran the binary. I also understood why the program was not updating when I ran it with just the base address. The first 4 bytes of the Sync Timer stored just the timer version. I was just reading this constant over and over again. But after first mapping the base physical address and adding the offset, the program read the actual timer value everytime. Here is the entire program (minus error checking):&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;constexpr uint32_t kTimerBase = 0x48320000;
constexpr uint32_t timer_offset = 0x0010; 


int main() {
    int memfd = open(&quot;/dev/mem&quot;, O_RDWR | O_SYNC);

    void *map_base = mmap(NULL, sizeof(uint32_t),
    PROT_READ | PROT_WRITE, MAP_SHARED,
    memfd, kTimerBase);

    uint32_t *timer = (uint32_t *)((char *)map_base + timer_offset);

    for (int i = 0; i &amp;lt; 10; i++) {
        std::cout &amp;lt;&amp;lt; &quot;System timer: &quot; &amp;lt;&amp;lt; *timer;
        std::cout &amp;lt;&amp;lt; std::endl;
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As an aside, the program as specified in the book, did not run correctly on the rPi emulator either. But once I made the offset changes above to the code, it read the timer value correctly on every run.&lt;/p&gt;</content><author><name>Arun</name></author><category term="programming" /><category term="cpp" /><category term="embedded" /><summary type="html">One of the exercises in the book ‘Embedded Programming with Modern C++ Cookbook’ is to read the System Timer on a RaspberryPi. The system timer peripheral on a raspberry pi provides a 64 bit free running counter that increments with every clock tick. Although the book uses QEMU to run a rPi emulator as the target for the programs, I have been using a Beagleboard XM as the target. So far, there have been some changes, but no significant differences in code for the raspberry pi vs the beagleboard. I assumed that reading the system timer would be no different. This was of course, not the case. For a beginner like myself, it was quite challenging to get it working on the bbxm.</summary></entry><entry><title type="html">Implementing TCP in Rust - Part 2</title><link href="http://localhost:4000/archive/implementing-tcp-in-rust-part2/" rel="alternate" type="text/html" title="Implementing TCP in Rust - Part 2" /><published>2022-04-16T00:00:00-07:00</published><updated>2022-04-16T00:00:00-07:00</updated><id>http://localhost:4000/archive/implementing-tcp-in-rust-part2</id><content type="html" xml:base="http://localhost:4000/archive/implementing-tcp-in-rust-part2/">&lt;p&gt;&lt;a href=&quot;https://arunvijayshankar.github.io/archive/implementing-tcp-in-rust/&quot;&gt;Part1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In my last &lt;a href=&quot;https://arunvijayshankar.github.io/archive/implementing-tcp-in-rust/&quot;&gt;post&lt;/a&gt; on @jonhoo’s live stream on implementing TCP in Rust, I covered everything upto the point where we parsed the source IP address, destination IP address, and payload length from the packet we received from a remote host. We emulated a remote host using a virtual interface, tun0, which we created using the TUN/TAP universal device driver. Picking up where we left off, in this post we explore the packet we received further, parse the TCP segment, and respond to the packet in a particular way, as is specified in &lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc793&quot;&gt;RFC 793&lt;/a&gt;, the TCP functional specification document.&lt;/p&gt;

&lt;p&gt;As we are trying to implement TCP, we can try to make a TCP connection using netcat to any port:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nc 198.168.0.2 80
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We see that 40 bytes are received of protocol 6, which is TCP.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post3/formatted_packet_tcp.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now that we have TCP packets, we can dive deeper into it, and go about actually implementing TCP. A good place to start that is RFC 793, which specifies the protocol in great detail. As an aside, it had never occurred to me to ask what it means to implement something like TCP. It simply means implement the expected behavior and rules as specified in the Standards document. For example, if the document says that a host (let’s say a server) that receives a SYN packet (which is a type of TCP segment, something we will go into detail in the next couple of posts) from a remote host (client), the server has to respond in a way that is specified in RFC 793. In the case of the SYN packet, the server can respond to the packet by either sending an ACK plus a SYN of it’s own, or choose to close the connection.&lt;/p&gt;

&lt;p&gt;To parse the TCP packets, we can use etherparse again. Another option is to write methods to parse the packets as well, but since most of the implementation of TCP has to do with bit manipulation, and not parsing, it is more convenient to let etherparse do all the heavy lifting here. With that out of the way, we can start with the actual details of the implementation. To begin with, there are two key objects we have to keep track of: the connection, which is identified by the source ip address, the source port, the destination ip address, and the destination port; and the state of the connection which can be either Listening, Closed, or Established, among others. The entire list of states can be found in RFC 793. We can store the the quad of values in the connection, and the state of the connection in structs, and have a hashmap from the quad to the state to hold all the connections.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
#[derive(Clone, Copy, Debug, Hash, Eq, PartialEq)]
struct Quad { // This struct identifies each connection
    src: (Ipv4Addr, u16), // (&amp;lt;ip_addr&amp;gt;, &amp;lt;port&amp;gt;)
    dst: (Ipv4Addr, u16),
}

enum State { // enum to hold connection state value
    // Listen,
    SynRcvd,
    Estab,
    FinWait1,
    FinWait2,
    TimeWait,
}

pub struct Connection { // struct to hold the state of a particular connection [src ip, src port, dest ip, dest src]
    state: State,
    send: SendSequenceSpace,
    recv: RecvSequenceSpace,
    ip: etherparse::Ipv4Header,
    tcp: etherparse::TcpHeader,
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The first thing to do when we receive a TCP segment is to make a connections entry for it. We store the src ip, src port, dest ip, and dest port in an instance of the Quad struct above, and check the hashmap if an entry exists for the connection. If one exists already, we have to deal with the packet. We implement this in a function called on_packet(). If there isn’t an entry in the hashmap for the connection, it is a new connection, and we will implement this functionality in a function called accept(). For now, we just print the quad values. When we run it now, we see all the data, and 0b of payload which indicates that it’s header only.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post4/formatted_packets_tcp_3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To see exactly what the the packet we received looks like, we can run tshark again and then start a TCP connection.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post4/tshark_screen_shot.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can see that the first packet we received was a SYN packet. Having received it, we have to decide how we should respond. To do this, we can refer to RFC 793 and see what is to be done next. The entire process flow can be summarized in the following diagram:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post4/proc_flow.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A connection can be in CLOSED: meaning we do not reply if we are sent a packet, or LISTEN, meaning if someone we are not speaking to atm, sends a packet we are always going to deal with that packet. In our implementation we are going to assume that every port is listening. Exploring the diagram a bit, we see that if someone sends us a SYN, we can either close the connection, or we can send an ACK and a SYN ourself. I.e., we acknowledge the SYN that was sent, and send a SYN of our own asking if the remote machine wants to establish a connection. If we receive an ACK for our SYN, the connection is then established. If we wish to establish a connection, we start of at CLOSED, from where we go to OPEN, and then send a SYN. If the remote machine sends a SYN and ACK, we send an ACK and the connection is established. In our implementation, we implement the server part first, and the client part later. Since we are in server mode, we never send out any packets first.&lt;/p&gt;

&lt;p&gt;If a SYN packet is received, we need to handle that and start establishing a connection. Basically we have to write a TCP header. We can use etherparse again for this, which has a new() method to create a TCP segment. it takes a source port, destination port, sequence number and window size. We already know that source port for our TCP header is the destination port from the received SYN packet, and the destination port is the source port from the same packet. Sequence number and window size are something we have to figure out. As we are now responding to the SYN received from remote host, we have to send SYN and ACK, so we have to set those two bits in the header. This will have to be wrapped in an ipv4 header to send it back to the remote host. Again we can use etherparse to create the header for us (with new), and this takes payload length which is equal to length of the SYN/ACK msg, the timeout set to 64, the protocol, in this case TCP, source and destination addresses. Once done, this packet will now have to be sent out.&lt;/p&gt;

&lt;p&gt;I will stop here for this post. In my next post I will cover the part of the live stream that talks about writing TCP segments and IP packets, what fields are to be written, how they are calculated, and finally how to send them out to the “remote host” (the client, in this implementation).&lt;/p&gt;</content><author><name>Arun</name></author><category term="programming" /><category term="rust" /><category term="networking" /><summary type="html">Part1</summary></entry><entry><title type="html">SSH over an OpenVPN connection</title><link href="http://localhost:4000/archive/ssh-over-an-openvpn-connection/" rel="alternate" type="text/html" title="SSH over an OpenVPN connection" /><published>2022-04-02T10:45:16-07:00</published><updated>2022-04-02T10:45:16-07:00</updated><id>http://localhost:4000/archive/ssh-over-an-openvpn-connection</id><content type="html" xml:base="http://localhost:4000/archive/ssh-over-an-openvpn-connection/">&lt;p&gt;&lt;em&gt;TL;DR&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;If you have an active OpenVPN connection to a remote linux machine, and are finding that you cannot ssh to it, try setting up port forwarding on your router config page to forward traffic from the OpenVPN port to the ssh port on your box. Configure the device IP on the config page to point to the local ip address of the linux machine. Connect over ssh with: &lt;em&gt;ssh host@local_ip_address&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;/TL;DR&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;About two years ago I bought a cheap desktop computer and installed Linux (Ubuntu, because I’m a noob) on it. I decided that I wanted to learn software development, and I wanted to do it on Linux. Setup was not without issues, and I still haven’t managed to get wifi working on it, but overall it was easy. I thought I would use the box for learning and writing code only, but it has become my primary home PC. I’m using it right now in writing this. The PC serves me very well, but almost immediately after setting it up, I realized I wanted to ssh into it from a remote host. Mainly from my laptop for when I work from bed.&lt;/p&gt;

&lt;p&gt;I looked up how to get ssh running on ubuntu and found lots of great guides on the topic. I configured the server, and added key based authentication for extra security. This was super easy and I was able to ssh into the linux box from my laptop. But because I am greedy, I wanted to be able to ssh into from outside my home network too. I looked up how to do that and when I saw that it meant I had to expose the ssh port to the internet at large, I was sufficiently put off to abandon the idea altogether. It also seemed to involve something called “port forwarding” which I don’t think I will ever truly understand. If anyone reading this post has any resources that explain port forwarding in a easy to understand fashion, I would appreciate it if you could send it my way.&lt;/p&gt;

&lt;p&gt;Now that I am a little older, and with about the same amount of wisdom, I decided to take another stab at it. Having worked from home for the past two years, and having acquired a better understanding of what VPNs are and how they work, I wondered if I could set up a home VPN and connect to that remotely. If I could do that, then I could ssh into the linux box from anywhere. Easy-peasy. After a bit of reading, I learnt that you can setup a VPN using your home router. I checked mine and found that it could setup a VPN. Mine has a couple of options for VPNs, but I choose OpenVPN becuase I had heard of it and becuase it said “secure” in the description. I intend to look into PPTP and L2TP/IPSec (the other options) a little later. I configured OpenVPN by following the online guide published for TP-Link routers. Configuring it on your router might be a little different. Searching for &lt;em&gt;router_name VPN setup&lt;/em&gt; should return setup guides for your router, if you wish to set one up. I also downloaded and installed the OpenVPN client on my laptop. I configured the client with the OpenVPN config file I generated on the Linux box (which is now the OpenVPN server).&lt;/p&gt;

&lt;p&gt;With all of this setup, I connected my laptop to a mobile hotspot using my phone to simulate an external network and tried to connect to the VPN. After a little bit of fiddling around with the server settings, I could connect to it. I tried pinging the server, and once I confirmed that it was working, I tried to connect over ssh. Which did not work. Server was rejecting my connections. So I went back to the internet. I found that while this is not a very common issue, it has been faced by quite a few people. The common diagnosis was that all traffic gets tunneled over the VPN, and we have to let the server know to deal with SSH traffic separately. Most fixes I read involved changing the ip table rules to do… something. I can’t say I understood what that was all about. Still, in true sw engineer fashion, I tried out the commands to edit the ip table. This did not work either, as the syntax for editing the ip table has either changed, or is different for ubuntu for some reason.&lt;/p&gt;

&lt;p&gt;I did find one post that specified allowing ssh over the OpenVPN port (which was configured when I set OpenVPN up) through the firewall. That seemed promising, so I tried it out. Still no luck. The server kept rejecting my ssh connections. I was about to give up once again, when I remembered one particular comment in one of the posts which suggested setting up NAT forwarding. I was still reluctant to try changing anything here, since, as mentioned earlier, I don’t really understand what port forwarding is. However, since I was grasping at straws at this point, I thought I’d give it a shot. And there it was, in the NAT forwarding tab in my router config page: “Port Forwarding”. The config page asked me to specify a device IP address, an internal port, and an external port. At first I tried the ssh port for both internal and external ports, which did not work at all. Then I realised that the external port was the port to which traffic was being sent, and the internal port was the port to which traffic was to be forwarded. The device IP address was to be set to the IP address of the device to which the traffic was to be forwarded. This became clear once I realized that when I connect to a VPN, I am essentially making a connection to my router, and not necessarily to any device on my home network. With port forwarding configured and enabled, I was able to ssh to my linux box from my laptop! I headed over to a cafe to try it out from an actual public networked and it worked there as well.&lt;/p&gt;

&lt;p&gt;It seems a little unbelievable that I have finally managed to solve something that I have been unsuccessful at on so many attempts in the past two years. I guess the lesson is, if a problem is being difficult, set it aside and try again at a different time. You might have learned something that turns to be the key to solving it.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PS&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;An interesting aside: I can ssh over the VPN if I use the IP address on my home subnet, but not when I use the IP address provided to the box by OpenVPN. I’m guessing that this is because I provided the home subnet IP address when I configured port forwarding on the router. But if I try and configure the OpenVPN IP address for port forwarding, the router rejects it, saying that it should have the same netmask as the router. Not sure if I can get around this. If anyone knows any way to ssh over OpenVPN with the IP address assigned by OpenVPN, please let me know!&lt;/p&gt;</content><author><name>Arun</name></author><category term="networking" /><category term="ssh" /><category term="vpn" /><summary type="html">TL;DR</summary></entry><entry><title type="html">Implementing TCP in Rust</title><link href="http://localhost:4000/archive/implementing-tcp-in-rust/" rel="alternate" type="text/html" title="Implementing TCP in Rust" /><published>2022-03-25T15:19:50-07:00</published><updated>2022-03-25T15:19:50-07:00</updated><id>http://localhost:4000/archive/implementing-tcp-in-rust</id><content type="html" xml:base="http://localhost:4000/archive/implementing-tcp-in-rust/">&lt;p&gt;One good thing about Twitter&lt;sup&gt;TM&lt;/sup&gt; is that once in a while I come across a tweet that voices out load the exact thing I was looking for. In this instance, I found this &lt;a href=&quot;https://twitter.com/b0rk/status/1505597582227165194&quot;&gt;tweet&lt;/a&gt; from &lt;a href=&quot;https://twitter.com/b0rk&quot;&gt;@b0rk&lt;/a&gt;, looking for networking courses. There were a lot of good suggestions, but this one caught my eye: &lt;a href=&quot;https://www.youtube.com/playlist?list=PLqbS7AVVErFivDY3iKAQk3_VAm8SXwt1X&quot;&gt;Implementing TCP&lt;/a&gt;, by &lt;a href=&quot;https://twitter.com/jonhoo&quot;&gt;@jonhoo&lt;/a&gt;. It is an implementation of TCP using Rust. It drew my eye immediately as learning Rust has been on my mind for a while now. Now, I do not know the first thing about Rust, and not very much more about networking, but I have found that I learn best by doing, so I drove right into it. Jon mentions RFC 1180 as a good tutorial to TCP/IP which I started reading  in parallel to the video series. I’m about 45 minutes into Part 1, and there are already a bunch of concepts with which I am completely unfamiliar. Nevertheless, just by following along, I was able to write a “virtual” NIC in rust. The only thing it does is read an IP packet as a bunch of bytes. Still, pretty cool. It wasn’t without hicups though. The setcap command did not work until I provided the entire path to the compiled binary, and for some reason $CARGO_TARGET_DIR, which I assumed was set during the setup, was not really set to anything. But barring these minor setbacks, the code compiled and ran pretty well.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post3/ip_packet_rcvd_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The first new rust concept i hit upon in the video was cargo. Cargo is the build and packaging system of Rust. I learned that it downloads the necessary libraries and builds your code. You list your projects dependencies (packages of code, called Crates) in the .toml file, and Cargo will download and link them for you. You can use cargo to build your code using “cargo build –release” and it will build and create your binaries in a separate folder. There are a bunch of options you can specify in the build command like ‘r’ to build your code, and then run it, or ‘b’ to only compile your code and build the binary.&lt;/p&gt;

&lt;p&gt;The tutorial introduced TUN/TAP next. This is a really cool kernel module that provides packet transmission and reception for User space programs. If I understand correctly, it creates a virtual network adapter to whom the kernel forwards packets from a user space program, and whose packets the kernel sends to the user space program. There is already a Rust crate for Tun/Tap bindings which is used in the tutorial. It’s a really cool module, and I’m sure I’ll be using it a lot in my networking adventures in the future. The actual syntax is very similar to C and Jon quickly covered the actual code by following the tun_tap docs closely.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
use std::io;

fn main() -&amp;gt; io::Result&amp;lt;()&amp;gt; {
	let nic = tun_tap::Iface::new(&quot;tun0&quot;, tun_tap::Mode::Tun)?;
	let mut buf = [0u8; 1504];
	let nbytes = nic.recv(&amp;amp;mut buf[..])?;
	eprintln!(&quot;read {} bytes: {:x?}&quot;, nbytes, &amp;amp;buf[..nbytes]);
	Ok(())
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A new thing in Rust is the syntax to use library functions. For example, to user a function called “some_function()” that is part of “some_library”, you would write: some_library::some_function(). A few other new things are “match”, OK(), Err(), and the “-&amp;gt;” and “=&amp;gt;” operators, but I will dive deeper into them as I move forward.&lt;/p&gt;

&lt;p&gt;To use TUN/TAP, we need CAP_NET_ADMIN privileges which is confirgured with the setcap command: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo setcap cap_net_admin=eip &amp;lt;path_to_target&amp;gt;&lt;/code&gt;. The tutorial uses $CARGO_TARGET_DIR in the path, but for some reason this did not work for me. I am not really sure if I have to set this variable myself, or if it gets set by cargo. In any case I was able to get around this by simply providing the relative path to the target. Finally, we compiled the code and ran it. Now when you run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ip addr&lt;/code&gt;, you can see tun0 show up in your list of network devices.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post3/tun0_offline.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As of now, tun0 is not really doing anything. To configure it to listen for IP packets we have to run the following commands:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
sudo ip addr add &amp;lt;some IP address&amp;gt; dev tun0

sudo ip link set up dev tun0

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;ip addr add &amp;lt;static IP address&amp;gt; dev &amp;lt;device name&amp;gt;&quot;&lt;/code&gt; adds an ip address to the newly created network device tun0, and once that’s done, we bring tun0 online with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;ip link set up dev &amp;lt;device name&amp;gt;&quot;&lt;/code&gt;. tun0 will now listen for IP packets and the code will display the bytes in the packet that tun0 received.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post3/tun0_online.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To simplify the whole process, all the individual commands were wrapped up in a shell file:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&amp;lt;#!/bin/bash
cargo b --release
sudo setcap cap_net_admin=eip &amp;lt;path to binary&amp;gt;
&amp;lt;path to binary&amp;gt; &amp;amp;
pid=$!
sudo ip addr add 192.168.0.1/24 dev tun0
sudo ip link set up dev tun0
trap &quot;kill $pid&quot; INT TERM
wait $pid

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and anytime we want trust to listen for IP packets sent to tun0, we can run the .sh file to compile any changes to the code, set cap_net_admin, run the program, and bring tun0 online.&lt;/p&gt;

&lt;p&gt;So now we can bring tun0 online and listen for packets, but the program will stop running once tun0 receives an IP packet. To keep tun0 listening indefinitely, we put it in a loop. Loop is a rust functionality that let’s you run an infinite loop. Just put your code in a block like so&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
loop {

	# code goes here

}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we can ping the IP address we set earlier, and the component bytes will be displayed consecutively. However, these bytes are not really readable to most of us, I would imagine. To make better sense of the data, a rust crate called etherparse can be used to parse the hex data and extract useful information from them. We choose to pull source IP, destination IP, payload length, and IP protocol.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
match etherparse::Ipv4HeaderSlice::from_slice(&amp;amp;buf[4..nbytes]) {
	Ok(p) =&amp;gt; {
		let src = p.source_addr();
		let dst = p.destination_addr();
		let protocol = p.protocol();
		eprintln!(
			&quot;{} -&amp;gt; {} {}b of protocol {}&quot;,
			src,
			dst,
			p.payload_len(),
			protocol
		);
	},
	Err(e) =&amp;gt; {
		eprintln!(&quot;ignoring weird packet {:?}&quot;, e);
	}
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When we run the wrapper, we see a nicely formatted, more informational strings:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post3/formatted_packets_ping.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can see that packets were sent to 192.168.0.2 from 192.168.0.1 with IP protocol 1, which is ICMP which is what ping uses. We can also use netcap to try and connect to the IP address (at any port) to see if it is reflected correctly:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/post3/formatted_packet_tcp.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can see that 40 bytes are received of protocol 6, which is TCP.&lt;/p&gt;

&lt;p&gt;This brings us to the end of the first 45 minutes of the tutorial. I will cover the rest of the tutorial in roughly one hour chunks, I think. Along with actually coding and ironing out issues, it takes me around an hour or so to get through 45 minutes of video, so it seems like a good duration. The tutorial is 13 hours in total, and I expect to complete it in a month or so. Ideally, I would like to finish it a lot sooner, but needs must, so 45 minutes at a time it will have to be.&lt;/p&gt;</content><author><name>Arun</name></author><category term="programming" /><category term="rust" /><category term="networking" /><summary type="html">One good thing about TwitterTM is that once in a while I come across a tweet that voices out load the exact thing I was looking for. In this instance, I found this tweet from @b0rk, looking for networking courses. There were a lot of good suggestions, but this one caught my eye: Implementing TCP, by @jonhoo. It is an implementation of TCP using Rust. It drew my eye immediately as learning Rust has been on my mind for a while now. Now, I do not know the first thing about Rust, and not very much more about networking, but I have found that I learn best by doing, so I drove right into it. Jon mentions RFC 1180 as a good tutorial to TCP/IP which I started reading in parallel to the video series. I’m about 45 minutes into Part 1, and there are already a bunch of concepts with which I am completely unfamiliar. Nevertheless, just by following along, I was able to write a “virtual” NIC in rust. The only thing it does is read an IP packet as a bunch of bytes. Still, pretty cool. It wasn’t without hicups though. The setcap command did not work until I provided the entire path to the compiled binary, and for some reason $CARGO_TARGET_DIR, which I assumed was set during the setup, was not really set to anything. But barring these minor setbacks, the code compiled and ran pretty well.</summary></entry><entry><title type="html">Password protection in python scripts</title><link href="http://localhost:4000/archive/password-protection-in-python-scripts/" rel="alternate" type="text/html" title="Password protection in python scripts" /><published>2022-03-08T19:50:00-08:00</published><updated>2022-03-08T19:50:00-08:00</updated><id>http://localhost:4000/archive/password-protection-in-python-scripts</id><content type="html" xml:base="http://localhost:4000/archive/password-protection-in-python-scripts/">&lt;p&gt;I came across an interesting problem recently. I was running a python script that would periodically update a remote database. It would connect to the database with a shared login credential and update a table. The script would run locally on multiple machines. Initially, the hashed db password was stored in the script, and extracted before being used to connect to the database.&lt;/p&gt;

&lt;p&gt;It was not too long before I realized that anyone with access to the script can straight up read the password without so much as a how do you do. I looked up password protection on the internet, and there are some good approaches out there, like using hashing with hashlib, storing the password in env values, or using Keyring to store and fetch the password. You can find a good tutorial on using them &lt;a href=&quot;https://martinheinz.dev/blog/59&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, these approaches face the same issue. Anyone with access to the machine the script is running on, can recover the password quite easily. I think only some form of secure handshake/authentication protocol can provide user authentication without storing the password in the script. The problem is, I do not know the first thing about setting up such a system. Especially with a DBMS with which I am unfamiliar. Also, I’m pretty sure the shared login is pretty much an immutable object (pun intended), and I cannot avoid using it. So I thought about it some more, and it occurred to me, that the only reason to keep the password in the script in the first place was because it used a connect_to_db module in the same script to connect to the database.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/db_conn_mod.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I realized that if I moved the entire connection module to a different file, and imported that file as a library in my script, my script would still have the db connection, but would not need the password in the script in any form. I could then use Keyring in the special connection library to retrieve a password that I store on the system separately, again using Keyring. But this just moves the problem to a different python file. To ensure that the password cannot be extracted from the connection lib file either, I hit upon the idea of compiling the lib file, and including only the byte file along with the main script. And that did it! The script works, and has at least somewhat better security than earlier.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/conn.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, this is still not very secure. It is very easy to de-compile the pyc file and extract the password from it. Still, some security is better than no security.&lt;/p&gt;</content><author><name>Arun</name></author><category term="programming" /><category term="python" /><summary type="html">I came across an interesting problem recently. I was running a python script that would periodically update a remote database. It would connect to the database with a shared login credential and update a table. The script would run locally on multiple machines. Initially, the hashed db password was stored in the script, and extracted before being used to connect to the database.</summary></entry></feed>